{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad30e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print('PIL 라이브러리 임포트 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3119ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 images to be resized\n",
      "66 images resized.\n",
      "가위 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "    images = glob.glob(img_path + '/*.jpg')\n",
    "    \n",
    "    print(len(images), 'images to be resized')\n",
    "    \n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, 'JPEG')\n",
    "        \n",
    "    print(len(images), 'images resized.')\n",
    "    \n",
    "image_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/scissor'\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print('가위 이미지 resize 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2200b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 images to be resized\n",
      "70 images resized.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/rock'\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf56449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 images to be resized\n",
      "70 images resized.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/paper'\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f57934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터의 이미지 개수는 2394 입니다.\n",
      "x_train shape (3000, 28, 28, 3)\n",
      "y_train shape (3000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=3000):\n",
    "    #가위0 바위1 보2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨데이터를 담을 행렬 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.*g'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img #데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/rock/*.*g'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img #데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1\n",
    "        idx=idx+1\n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.*g'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img #데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2\n",
    "        idx=idx+1\n",
    "    \n",
    "    print('학습데이터의 이미지 개수는', idx,'입니다.')\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper'\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0 #입력은 0~1사이의 값으로 정규화\n",
    "\n",
    "print('x_train shape {}'.format(x_train.shape))\n",
    "print('y_train shape {}'.format(y_train.shape))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8d459e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨:', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf98a2d",
   "metadata": {},
   "source": [
    "딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfe76f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 31,050\n",
      "Trainable params: 31,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=8\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(2,2))#풀링 층\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9aeb7a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "10/10 [==============================] - 1s 16ms/step - loss: 15.6736 - accuracy: 0.5700\n",
      "Epoch 2/8\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.2469 - accuracy: 0.7533\n",
      "Epoch 3/8\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0170 - accuracy: 0.8700\n",
      "Epoch 4/8\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6787 - accuracy: 0.9767\n",
      "Epoch 5/8\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6060 - accuracy: 0.9900\n",
      "Epoch 6/8\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5105 - accuracy: 1.0000\n",
      "Epoch 7/8\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.3938 - accuracy: 1.0000\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.2527 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7a632e029280>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29803b",
   "metadata": {},
   "source": [
    "테스트 데이터 불러오기(웹캠 없는사람용 3년전 데이터 가져옴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "482a5174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images to be resized\n",
      "100 images resized.\n",
      "100 images to be resized\n",
      "100 images resized.\n",
      "100 images to be resized\n",
      "100 images resized.\n"
     ]
    }
   ],
   "source": [
    "testrock_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/test/test/rock'\n",
    "testscissor_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/test/test/scissor'\n",
    "testpaper_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/test/test/paper'\n",
    "\n",
    "resize_images(testrock_dir_path)\n",
    "resize_images(testscissor_dir_path)\n",
    "resize_images(testpaper_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "781acee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "testimg_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/test/test'\n",
    "\n",
    "(x_test, y_test)=load_data(testimg_dir_path)\n",
    "\n",
    "x_test_norm = x_test/255.0\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a2389c",
   "metadata": {},
   "source": [
    "test_accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e4e2d4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 9.7616 - accuracy: 0.3333\n",
      "test_loss: 9.76156997680664\n",
      "test_accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'test_loss: {test_loss}')\n",
    "print(f'test_accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc9c18",
   "metadata": {},
   "source": [
    "# 모델 수정해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "302ad12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 images to be resized\n",
      "750 images resized.\n",
      "가위 이미지 resize 완료\n",
      "726 images to be resized\n",
      "726 images resized.\n",
      "바위 이미지 resize 완료\n",
      "712 images to be resized\n",
      "712 images resized.\n",
      "보 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "#일단 학습데이터 늘려보기, 캐글에서 받은 png파일 변환하기\n",
    "def resize_pngimages(img_path):\n",
    "    images = glob.glob(img_path + '/*.png')\n",
    "    \n",
    "    print(len(images), 'images to be resized')\n",
    "    \n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, 'JPEG')\n",
    "        \n",
    "    print(len(images), 'images resized.')\n",
    "    \n",
    "image_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/scissor'\n",
    "resize_pngimages(image_dir_path)\n",
    "print('가위 이미지 resize 완료')\n",
    "\n",
    "image_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/rock'\n",
    "resize_pngimages(image_dir_path)\n",
    "print('바위 이미지 resize 완료')\n",
    "\n",
    "image_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/paper'\n",
    "resize_pngimages(image_dir_path)\n",
    "print('보 이미지 resize 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21083d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터의 이미지 개수는 2394 입니다.\n",
      "x_train shape (3000, 28, 28, 3)\n",
      "y_train shape (3000,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper'\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0\n",
    "\n",
    "print('x_train shape {}'.format(x_train.shape))\n",
    "print('y_train shape {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "075c7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 0.0114 - accuracy: 0.9973\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 0.0333 - accuracy: 0.9923\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 0.0076 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7a632c222a30>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_channel_1=8\n",
    "n_channel_2=16\n",
    "n_dense=32\n",
    "n_train_epoch=3 #하이퍼파라미터 조정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f38722f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터의 이미지 개수는 300 입니다.\n",
      "x_test shape: (3000, 28, 28, 3)\n",
      "y_test shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "testimg_dir_path = os.getenv('HOME') + '/aiffel/rock_scissor_paper/test/test'\n",
    "(x_test, y_test)=load_data(testimg_dir_path)\n",
    "x_test_norm = x_test/255.0\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0a4b988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 1s - loss: 0.6097 - accuracy: 0.9390\n",
      "test_loss: 0.6097202301025391\n",
      "test_accuracy: 0.9390000104904175\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'test_loss: {test_loss}')\n",
    "print(f'test_accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e3b26",
   "metadata": {},
   "source": [
    "그냥 좋은 데이터를 많이 넣으니까 성능이 좋아졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195293f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
